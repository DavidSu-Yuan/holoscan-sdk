%YAML 1.2
# SPDX-FileCopyrightText: Copyright (c) 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
extensions:
  # extensions are automatically loaded upon Python App initialization so
  # should not be included again here

source: "replayer" # or "aja"
do_record: false # or 'true' if you want to record input video stream.

aja:
  width: 1920
  height: 1080
  rdma: true
  enable_overlay: false
  overlay_rdma: true

replayer:
  directory: "../data/endoscopy/video"
  basename: "surgical_video"
  frame_rate: 0 # as specified in timestamps
  repeat: true # default: false
  realtime: true # default: true
  count: 0 # default: 0 (no frame count restriction)

recorder_format_converter:
  in_dtype: "rgba8888"
  out_dtype: "rgb888"

recorder:
  directory: "/tmp"
  basename: "tensor"

format_converter_replayer:
  out_tensor_name: source_video
  out_dtype: "float32"
  scale_min: 0.0
  scale_max: 255.0

format_converter_aja:
  in_dtype: "rgba8888"
  out_tensor_name: source_video
  out_dtype: "float32"
  scale_min: 0.0
  scale_max: 255.0
  resize_width: 854
  resize_height: 480

lstm_inference:
  input_tensor_names:
    - source_video
    - cellstate_in
    - hiddenstate_in
  input_state_tensor_names:
    - cellstate_in
    - hiddenstate_in
  input_binding_names:
    - data_ph:0 # (shape=[1, 480, 854, 3], dtype=float32) <==> source_video
    - cellstate_ph:0 # (shape=[1, 60, 107, 7], dtype=float32) == internal state
    - hiddenstate_ph:0 # (shape=[1, 60, 107, 7], dtype=float32) == internal state
  output_tensor_names:
    - cellstate_out
    - hiddenstate_out
    - probs
    - scaled_coords
    - binary_masks
  output_state_tensor_names:
    - cellstate_out
    - hiddenstate_out
  output_binding_names:
    - Model/net_states:0 # (shape=[ 1, 60, 107, 7], dtype=float32)
    - Model/net_hidden:0 # (shape=[ 1, 60, 107, 7], dtype=float32)
    - probs:0 # (shape=[1, 7], dtype=float32)
    - Localize/scaled_coords:0 # (shape=[1, 7, 2], dtype=float32)
    - Localize_1/binary_masks:0 # (shape=[1, 7, 60, 107], dtype=float32)
  force_engine_update: false
  verbose: true
  max_workspace_size: 2147483648
  enable_fp16_: true


segmentation_inference:  # TensorRtInference
  input_tensor_names:
    - source_video
  input_binding_names:
    - INPUT__0
  output_tensor_names:
    - inference_output_tensor
  output_binding_names:
    - OUTPUT__0
  force_engine_update: false
  verbose: true
  max_workspace_size: 2147483648
  enable_fp16_: false


visualizer_format_converter_replayer:
  in_dtype: "rgb888"
  out_dtype: "rgba8888"
  out_tensor_name: video

visualizer_format_converter_aja:
  in_dtype: "rgba8888"
  out_dtype: "rgba8888"
  resize_width: 854
  resize_height: 480
  out_tensor_name: video

visualizer:
  videoframe_vertex_shader_path: gxf_extensions/visualizer_tool_tracking/glsl/viewport_filling_triangle.vert
  videoframe_fragment_shader_path: gxf_extensions/visualizer_tool_tracking/glsl/video_frame.frag
  tooltip_vertex_shader_path: gxf_extensions/visualizer_tool_tracking/glsl/instrument_tip.vert
  tooltip_fragment_shader_path: gxf_extensions/visualizer_tool_tracking/glsl/instrument_tip.frag
  overlay_img_vertex_shader_path: gxf_extensions/visualizer_tool_tracking/glsl/viewport_filling_triangle.vert
  overlay_img_fragment_shader_path: gxf_extensions/visualizer_tool_tracking/glsl/instrument_mask.frag
  overlay_img_width: 107
  overlay_img_height: 60
  overlay_img_channels: 1
  overlay_img_layers: 7
  num_tool_classes: 7
  num_tool_pos_components: 2
  tool_labels:
    - Grasper
    - Bipolar
    - Hook
    - Scissors
    - Clipper
    - Irrigator
    - Spec.Bag
  label_sans_font_path: gxf_extensions/visualizer_tool_tracking/fonts/Roboto-Regular.ttf
  label_sans_bold_font_path: gxf_extensions/visualizer_tool_tracking/fonts/Roboto-Bold.ttf
  in_tensor_names:
    - video
    - probs
    - net_states
    - binary_masks
    - scaled_coords
  in_width: 854
  in_height: 480
  in_channels: 4
  in_bytes_per_pixel: 1

tool_tracking_postprocessor:

holoviz:
  width: 854
  height: 480
  headless: false
  enable_render_buffer_input: false
  enable_render_buffer_output: true
  tensors:
    - name: ""
      type: color
      opacity: 1.0
      priority: 0
    - name: mask
      type: color
      opacity: 1.0
      priority: 1
    - name: scaled_coords
      type: crosses
      opacity: 1.0
      line_width: 4
      color: [1.0, 0.0, 0.0, 1.0]
      priority: 2
    - name: scaled_coords
      type: text
      opacity: 1.0
      priority: 3
      color: [1.0, 1.0, 1.0, 0.9]
      text:
        - Grasper
        - Bipolar
        - Hook
        - Scissors
        - Clipper
        - Irrigator
        - Spec.Bag

multiai_inference:
  backend: "trt"
  pre_processor_map:
    "icardio_plax_chamber": ["plax_cham_pre_proc"]
    "icardio_aortic_stenosis": ["aortic_pre_proc"]
    "icardio_bmode_perspective": ["bmode_pre_proc"]
  inference_map:
    "icardio_plax_chamber": "plax_cham_infer"
    "icardio_aortic_stenosis": "aortic_infer"
    "icardio_bmode_perspective": "bmode_infer"
  in_tensor_names: ["plax_cham_pre_proc", "aortic_pre_proc", "bmode_pre_proc"]
  out_tensor_names: ["plax_cham_infer", "aortic_infer", "bmode_infer"]
  parallel_inference: true
  infer_on_cpu: false
  enable_fp16: false
  input_on_cuda: true
  output_on_cuda: true
  transmit_on_cuda: true

multiai_postprocessor:
  process_operations:
    "plax_cham_infer": ["max_per_channel_scaled"]
  processed_map:
    "plax_cham_infer": "plax_chamber_processed"
  in_tensor_names: ["plax_cham_infer",
                    "aortic_infer",
                    "bmode_infer"]
  out_tensor_names : ["plax_chamber_processed"]
  input_on_cuda: false
  output_on_cuda: false
  transmit_on_cuda: false

visualizer_icardio:
  in_tensor_names: ["plax_chamber_processed"]
  out_tensor_names: ["keypoints", "keyarea_1", "keyarea_2",
                     "keyarea_3", "keyarea_4", "keyarea_5", "lines"]
  input_on_cuda: false

emergent:
  width: 4200
  height: 2160
  framerate: 240
  rdma: false

demosaic:
  generate_alpha: false
  bayer_grid_pos: 2
  interpolation_mode: 0 # this is the only interpolation mode supported by NPP currently
